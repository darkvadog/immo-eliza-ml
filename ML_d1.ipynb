{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data\n",
    "### 1. Split your data into categorical and numerical columns\n",
    "### 2. One-Hot Encode Categorical Features: \n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "data_onehot = onehot_encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "### 3. Impute Missing Values with MICE:\n",
    "#### Initialize MICE with the one-hot encoded data and numerical features:\n",
    "missing_vars = [col for col in data_onehot.columns] + numerical_features\n",
    "imputer = mice(data[missing_vars], printflag=False)\n",
    "data_imputed = imputer.complete()\n",
    "\n",
    "#### 4. Rescale Numerical Features (Optional):\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed[numerical_features])\n",
    "\n",
    "### 5. Combine Preprocessed Data:\n",
    "#### Create a new DataFrame combining the one-hot encoded categories, imputed numerical features, and optionally scaled numerical features:\n",
    "data_preprocessed = pd.concat([pd.DataFrame(data_onehot, columns=onehot_encoder.get_feature_names(categorical_features)),\n",
    "                              pd.DataFrame(data_imputed[numerical_features], columns=numerical_features),\n",
    "                              pd.DataFrame(data_scaled) if \"data_scaled\" in locals() else pd.DataFrame()], axis=1)\n",
    "\n",
    "### 6. Create Reusable Pipeline:\n",
    "#### Wrap the steps into a function like the previous example, ensuring the correct order:\n",
    "def preprocess_data(data):\n",
    "  \"\"\"\n",
    "  Preprocesses data for machine learning, considering MICE for missing values.\n",
    "\n",
    "  Args:\n",
    "    data: A pandas DataFrame containing the data to preprocess.\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame containing the preprocessed data, \n",
    "    a OneHotEncoder object, and a mice object.\n",
    "  \"\"\"\n",
    "\n",
    "  # One-hot encode categorical features\n",
    "  categorical_features = [col for col in data.columns if col.startswith(\"fl_\")]\n",
    "  onehot_encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "  data_onehot = onehot_encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "  # Impute missing values with MICE\n",
    "  missing_vars = [col for col in data_onehot.columns] + [col for col in data.columns if not col.startswith(\"fl_\") and not col.endswith(\"_sqm\")]\n",
    "  imputer = mice(data[missing_vars], printflag=False)\n",
    "  data_imputed = imputer.complete()\n",
    "\n",
    "  # Optionally scale numerical features\n",
    "  numerical_features = [col for col in data.columns if not col.startswith(\"fl_\") and not col.endswith(\"_sqm\")]\n",
    "  scaler = StandardScaler()\n",
    "  data_scaled = scaler.fit_transform(data_imputed[numerical_features])\n",
    "\n",
    "  # Combine preprocessed data\n",
    "  data_preprocessed = pd.concat([pd.DataFrame(data_onehot, columns=onehot_encoder.get_feature_names(categorical_features)),\n",
    "                                pd.DataFrame(data_imputed[numerical_features], columns=numerical_features),\n",
    "                                pd.DataFrame(data_scaled) if \"data_scaled\" in locals() else pd.DataFrame()], axis=1)\n",
    "\n",
    "  return data_preprocessed, onehot_encoder, imputer\n",
    "\n",
    "\n",
    "MICE is available in several python libraries like mice and missForest. \n",
    "1. Import the library and initialize MICE\n",
    "2. Impute missing values\n",
    "3. Combine with remaining processing steps:\n",
    "You can integrate the MICE imputation step into your existing pipeline by replacing the SimpleImputer step with MICE. Remember to adapt the missing_vars list based on the actual variables containing missing data in your dataset.\n",
    "\n",
    "Important considerations:\n",
    "MICE requires categorical variables to be one-hot encoded before imputation. Ensure you one-hot encode the relevant categorical features before applying MICE.\n",
    "MICE generates multiple imputed datasets. Remember to combine them using appropriate techniques like pooling or Rubin's rules when interpreting your model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Split your data into categorical and numerical columns:\n",
    "data = pd.read_csv('data\\\\properties.csv')\n",
    "# Separate object and numerical columns\n",
    "object_cols = data.select_dtypes(include=['object'])\n",
    "numeric_cols = data.select_dtypes(include=['int64', 'float64'])\n",
    "equiped_nan_count = data['equipped_kitchen'].isna().sum()\n",
    "print(equiped_nan_count)\n",
    "# One-hot encode categorical features using pd.get_dummies\n",
    "encoded_object_cols = pd.get_dummies(object_cols, drop_first=True)\n",
    "# Combine encoded object and numerical columns\n",
    "combined_df = pd.concat([encoded_object_cols, numeric_cols], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
